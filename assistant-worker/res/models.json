[
  {
    "name": "GPT-5",
    "provider": "OpenAI",
    "contextWindow": 400000,
    "maxOutputTokens": 128000,
    "inputCostPer1M": 1.25,
    "cachedInputCostPer1M": 0.125,
    "outputCostPer1M": 10.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our flagship model for coding, reasoning, and agentic tasks across domains. It is a unified system that includes a fast model for routine queries and a deeper reasoning model for more complex problems.",
    "category": "gpt-5"
  },
  {
    "name": "GPT-5 mini",
    "provider": "OpenAI",
    "contextWindow": 400000,
    "maxOutputTokens": 128000,
    "inputCostPer1M": 0.25,
    "cachedInputCostPer1M": 0.025,
    "outputCostPer1M": 2.0,
    "vision": true,
    "functionCalling": true,
    "description": "A faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
    "category": "gpt-5"
  },
  {
    "name": "GPT-5 nano",
    "provider": "OpenAI",
    "contextWindow": 400000,
    "maxOutputTokens": 128000,
    "inputCostPer1M": 0.05,
    "cachedInputCostPer1M": 0.005,
    "outputCostPer1M": 0.4,
    "vision": true,
    "functionCalling": true,
    "description": "Our fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
    "category": "gpt-5"
  },
  {
    "name": "o3-deep-research",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 10.0,
    "cachedInputCostPer1M": 2.5,
    "outputCostPer1M": 40.0,
    "vision": true,
    "functionCalling": false,
    "description": "Our most advanced model for deep research, designed to tackle complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data—brought in through MCP connectors.",
    "category": "o-series"
  },
  {
    "name": "o4-mini-deep-research",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 2.0,
    "cachedInputCostPer1M": 0.5,
    "outputCostPer1M": 8.0,
    "vision": true,
    "functionCalling": false,
    "description": "Our faster, more affordable deep research model—ideal for tackling complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data, brought in through MCP connectors.",
    "category": "o-series"
  },
  {
    "name": "o3-pro",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 20.0,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 80.0,
    "vision": true,
    "functionCalling": true,
    "description": "A version of o3 with more compute to think harder and provide consistently better answers. It is designed to tackle tough problems, and some requests may take several minutes to finish.",
    "category": "o-series"
  },
  {
    "name": "gpt-audio",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 2.5,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 10.0,
    "vision": false,
    "functionCalling": true,
    "description": "Our first generally available audio model. It accepts audio inputs and outputs, and can be used in the Chat Completions REST API.",
    "category": "other"
  },
  {
    "name": "gpt-realtime",
    "provider": "OpenAI",
    "contextWindow": 32000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 4.0,
    "cachedInputCostPer1M": 0.4,
    "outputCostPer1M": 16.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our first general-availability realtime model, capable of responding to audio and text inputs in realtime over WebRTC, WebSocket, or SIP connections.",
    "category": "other"
  },
  {
    "name": "o3",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 2.0,
    "cachedInputCostPer1M": 0.5,
    "outputCostPer1M": 8.0,
    "vision": true,
    "functionCalling": true,
    "description": "A well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It is succeeded by GPT-5.",
    "category": "o-series"
  },
  {
    "name": "o4-mini",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 1.1,
    "cachedInputCostPer1M": 0.275,
    "outputCostPer1M": 4.4,
    "vision": true,
    "functionCalling": true,
    "description": "Our latest small o-series model. It's optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. It's succeeded by GPT-5 mini.",
    "category": "o-series"
  },
  {
    "name": "GPT-4.1",
    "provider": "OpenAI",
    "contextWindow": 1047576,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 2.0,
    "cachedInputCostPer1M": 0.5,
    "outputCostPer1M": 8.0,
    "vision": true,
    "functionCalling": true,
    "description": "GPT-4.1 excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step. Note that we recommend starting with GPT-5 for complex tasks.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4.1 mini",
    "provider": "OpenAI",
    "contextWindow": 1047576,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.4,
    "cachedInputCostPer1M": 0.1,
    "outputCostPer1M": 1.6,
    "vision": true,
    "functionCalling": true,
    "description": "A smaller, faster, and more cost-efficient version of GPT-4.1. It excels at instruction following and tool calling and is a good option for more complex tasks where latency and cost are a concern.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4.1 nano",
    "provider": "OpenAI",
    "contextWindow": 1047576,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.1,
    "cachedInputCostPer1M": 0.025,
    "outputCostPer1M": 0.4,
    "vision": true,
    "functionCalling": true,
    "description": "The fastest, most cost-efficient version of the GPT-4.1 series. It excels at instruction following and tool calling. It features a 1M token context window, and is ideal for tasks that demand low latency.",
    "category": "gpt-4"
  },
  {
    "name": "o1-pro",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 150.0,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 600.0,
    "vision": true,
    "functionCalling": true,
    "description": "A version of o1 with more compute to think harder and provide consistently better answers. It is available only in the Responses API.",
    "category": "o-series"
  },
  {
    "name": "computer-use-preview",
    "provider": "OpenAI",
    "contextWindow": 8192,
    "maxOutputTokens": 1024,
    "inputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 12.0,
    "vision": true,
    "functionCalling": true,
    "description": "A specialized model for the computer use tool. It is trained to understand and execute computer tasks. This model is only usable in the Responses API.",
    "category": "other"
  },
  {
    "name": "GPT-4o mini Search Preview",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 0.15,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 0.6,
    "vision": false,
    "functionCalling": false,
    "description": "A specialized model for web search with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call.",
    "category": "other"
  },
  {
    "name": "GPT-4o Search Preview",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 2.5,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 10.0,
    "vision": false,
    "functionCalling": false,
    "description": "A specialized model for web search with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call.",
    "category": "other"
  },
  {
    "name": "GPT-4.5 Preview (Deprecated)",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 75.0,
    "cachedInputCostPer1M": 37.5,
    "outputCostPer1M": 150.0,
    "vision": true,
    "functionCalling": true,
    "description": "A research preview of GPT-4.5. We recommend using gpt-4.1 or o3 models instead for most use cases. This model is deprecated.",
    "category": "gpt-4"
  },
  {
    "name": "o3-mini",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 1.1,
    "cachedInputCostPer1M": 0.55,
    "outputCostPer1M": 4.4,
    "vision": false,
    "functionCalling": true,
    "description": "Our newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini supports key developer features, like Structured Outputs, function calling, and Batch API.",
    "category": "o-series"
  },
  {
    "name": "GPT-4o mini Realtime",
    "provider": "OpenAI",
    "contextWindow": 16000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": {
      "text": 0.6,
      "audio": 10.0
    },
    "cachedInputCostPer1M": {
      "text": 0.3,
      "audio": 0.3
    },
    "outputCostPer1M": {
      "text": 2.4,
      "audio": 20.0
    },
    "vision": false,
    "functionCalling": true,
    "description": "A preview release of the GPT-4o-mini Realtime model, capable of responding to audio and text inputs in realtime over WebRTC or a WebSocket interface.",
    "category": "other"
  },
  {
    "name": "o1",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 15.0,
    "cachedInputCostPer1M": 7.5,
    "outputCostPer1M": 60.0,
    "vision": true,
    "functionCalling": true,
    "description": "A previous full o-series reasoning model. It's trained with reinforcement learning to perform complex reasoning by generating a long internal chain of thought before responding to the user.",
    "category": "o-series"
  },
  {
    "name": "omni-moderation",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 0,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 0,
    "vision": true,
    "functionCalling": false,
    "description": "A free model designed to detect harmful content. This is our most capable moderation model, accepting images as input as well.",
    "category": "other"
  },
  {
    "name": "o1-mini",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 1.1,
    "cachedInputCostPer1M": 0.55,
    "outputCostPer1M": 4.4,
    "vision": false,
    "functionCalling": false,
    "description": "A faster and more affordable reasoning model, optimized for STEM-related reasoning (math, coding, science) and designed to 'think' through problems with an internal chain of thought before responding. It is a smaller alternative to o1.",
    "category": "o-series"
  },
  {
    "name": "o1 Preview",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 15.0,
    "cachedInputCostPer1M": 7.5,
    "outputCostPer1M": 60.0,
    "vision": false,
    "functionCalling": true,
    "description": "A research preview of our first o-series reasoning model. It's trained with reinforcement learning to perform complex reasoning and thinks before answering by producing a long internal chain of thought.",
    "category": "o-series"
  },
  {
    "name": "GPT-4o",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 2.5,
    "cachedInputCostPer1M": 1.25,
    "outputCostPer1M": 10.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4o Audio",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": {
      "text": 2.5,
      "audio": 40.0
    },
    "cachedInputCostPer1M": null,
    "outputCostPer1M": {
      "text": 10.0,
      "audio": 80.0
    },
    "vision": false,
    "functionCalling": true,
    "description": "A preview release of the GPT-4o Audio models that accept audio inputs and outputs, and can be used in the Chat Completions REST API.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4o mini",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 0.15,
    "cachedInputCostPer1M": 0.075,
    "outputCostPer1M": 0.6,
    "vision": true,
    "functionCalling": true,
    "description": "A fast, affordable small model for focused tasks. It accepts both text and image inputs, and produces text outputs. It is ideal for fine-tuning, and model outputs from a larger model can be distilled to it to produce similar results at lower cost and latency.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4o mini Audio",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": {
      "text": 0.15,
      "audio": 10.0
    },
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": {
      "text": 0.6,
      "audio": 20.0
    },
    "vision": false,
    "functionCalling": true,
    "description": "A preview release of the smaller GPT-4o Audio mini model. It's designed to input audio or create audio outputs via the REST API.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4o Realtime",
    "provider": "OpenAI",
    "contextWindow": 32000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": {
      "text": 5.0,
      "audio": 40.0
    },
    "cachedInputCostPer1M": {
      "text": 2.5,
      "audio": 2.5
    },
    "outputCostPer1M": {
      "text": 20.0,
      "audio": 80.0
    },
    "vision": false,
    "functionCalling": true,
    "description": "A preview release of the GPT-4o Realtime model, capable of responding to audio and text inputs in realtime over WebRTC or a WebSocket interface.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4 Turbo",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 10.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 30.0,
    "vision": true,
    "functionCalling": true,
    "description": "An older high-intelligence GPT model. It was designed to be a cheaper, better version of GPT-4. Today, we recommend using a newer model like GPT-4o.",
    "category": "gpt-4"
  },
  {
    "name": "babbage-002",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 0.4,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 0.4,
    "vision": false,
    "functionCalling": false,
    "description": "A replacement for the deprecated GPT-3 ada and babbage base models. It is not trained with instruction following and is accessed through the legacy Completions API. Most customers should use GPT-3.5 or GPT-4.",
    "category": "gpt-3"
  },
  {
    "name": "ChatGPT-4o",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 5.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 15.0,
    "vision": true,
    "functionCalling": null,
    "description": "The GPT-4o snapshot currently used in ChatGPT. OpenAI recommends using an API model like GPT-5 or GPT-4o for most API integrations, but this model can be used to test the latest improvements for chat use cases.",
    "category": "gpt-4"
  },
  {
    "name": "codex-mini-latest",
    "provider": "OpenAI",
    "contextWindow": 200000,
    "maxOutputTokens": 100000,
    "inputCostPer1M": 1.5,
    "cachedInputCostPer1M": 0.375,
    "outputCostPer1M": 6.0,
    "vision": true,
    "functionCalling": true,
    "description": "A fine-tuned version of o4-mini specifically for use in Codex CLI. It is a fast reasoning model optimized for the Codex CLI.",
    "category": "o-series"
  },
  {
    "name": "DALL·E 2",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "pricingPerImage": {
      "1024x1024": 0.016,
      "1024x1536": 0.018,
      "1536x1024": 0.02
    },
    "vision": false,
    "functionCalling": false,
    "description": "An older AI image generation system that creates realistic images and art from a natural language description. It offers more control in prompting and allows for more requests at once compared to DALL·E 3.",
    "category": "image-generation"
  },
  {
    "name": "DALL·E 3",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "pricingPerImage": {
      "standard": {
        "1024x1024": 0.04,
        "1024x1536": 0.08,
        "1536x1024": 0.08
      },
      "hd": {
        "1024x1024": 0.08,
        "1024x1536": 0.12,
        "1536x1024": 0.12
      }
    },
    "vision": false,
    "functionCalling": false,
    "description": "An AI image generation system that creates realistic images and art from a natural language description. It understands significantly more nuance and detail than previous systems, and is built natively on ChatGPT for improved prompt interpretation and refinement.",
    "category": "image-generation"
  },
  {
    "name": "davinci-002",
    "provider": "OpenAI",
    "contextWindow": 16384,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 2.0,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 2.0,
    "vision": false,
    "functionCalling": false,
    "description": "A replacement for the deprecated GPT-3 curie and davinci base models. It is a smaller, faster model primarily used for fine-tuning tasks. It can understand and generate natural language or code but is not trained with instruction following.",
    "category": "gpt-3"
  },
  {
    "name": "GPT-3.5 Turbo",
    "provider": "OpenAI",
    "contextWindow": 16385,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 0.5,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 1.5,
    "vision": false,
    "functionCalling": null,
    "description": "A legacy GPT model optimized for chat. As of July 2024, GPT-4o mini is recommended as a cheaper, more capable, multimodal, and equally fast alternative.",
    "category": "gpt-3.5"
  },
  {
    "name": "GPT-4",
    "provider": "OpenAI",
    "contextWindow": 8192,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 30.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 60.0,
    "vision": true,
    "functionCalling": false,
    "description": "An older, high-intelligence GPT model that can process both text and images. It is a predecessor to GPT-4o and is generally slower and more expensive, though it can still be used for tasks requiring nuanced analysis.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4 Turbo Preview",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 10.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 30.0,
    "vision": true,
    "functionCalling": true,
    "description": "A research preview of an older, high-intelligence GPT model with a significantly larger context window than its predecessor. It offers improved instruction following, JSON mode, and parallel function calling. It is not recommended for production use.",
    "category": "gpt-4"
  },
  {
    "name": "GPT-4o mini Transcribe",
    "provider": "OpenAI",
    "contextWindow": 16000,
    "maxOutputTokens": 2000,
    "inputCostPer1M": {
      "text": 1.25,
      "audio": 3.0
    },
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 5.0,
    "vision": false,
    "functionCalling": false,
    "description": "A speech-to-text model that uses GPT-4o mini to transcribe audio. It offers improved word error rate, and better language recognition and accuracy compared to the original Whisper models.",
    "category": "transcription"
  },
  {
    "name": "GPT-4o mini TTS",
    "provider": "OpenAI",
    "contextWindow": 2000,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.6,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 12.0,
    "vision": false,
    "functionCalling": false,
    "description": "A text-to-speech model built on GPT-4o mini. It's used to convert text to natural sounding spoken text.",
    "category": "speech-generation"
  },
  {
    "name": "GPT-4o Transcribe",
    "provider": "OpenAI",
    "contextWindow": 16000,
    "maxOutputTokens": 2000,
    "inputCostPer1M": {
      "text": 2.5,
      "audio": 6.0
    },
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 10.0,
    "vision": false,
    "functionCalling": false,
    "description": "A speech-to-text model that uses GPT-4o to transcribe audio. It offers improvements to word error rate and better language recognition and accuracy compared to the original Whisper models.",
    "category": "transcription"
  },
  {
    "name": "GPT-5 Chat",
    "provider": "OpenAI",
    "contextWindow": 128000,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 1.25,
    "cachedInputCostPer1M": 0.125,
    "outputCostPer1M": 10.0,
    "vision": true,
    "functionCalling": true,
    "description": "GPT-5 Chat is the GPT-5 model currently in use by ChatGPT. It is recommended for testing the latest improvements for chat use cases, and is a powerful multimodal model for reasoning, coding, and general tasks.",
    "category": "gpt-5"
  },
  {
    "name": "GPT Image 1",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": {
      "text": 5.0,
      "image_input": 10.0
    },
    "cachedInputCostPer1M": {
      "text": 1.25,
      "image_input": 2.5
    },
    "outputCostPer1M": {
      "image_output": 40.0
    },
    "pricingPerImage": {
      "low": {
        "1024x1024": 0.011,
        "1024x1536": 0.016,
        "1536x1024": 0.016
      },
      "medium": {
        "1024x1024": 0.042,
        "1024x1536": 0.063,
        "1536x1024": 0.063
      },
      "high": {
        "1024x1024": 0.167,
        "1024x1536": 0.25,
        "1536x1024": 0.25
      }
    },
    "vision": true,
    "functionCalling": false,
    "description": "A state-of-the-art image generation model. It is a natively multimodal language model that accepts both text and image inputs and produces image outputs. It is known for its ability to follow precise instructions and render text accurately.",
    "category": "image-generation"
  },
  {
    "name": "gpt-oss-120b",
    "provider": "OpenAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.25,
    "cachedInputCostPer1M": 0,
    "outputCostPer1M": 0.69,
    "vision": false,
    "functionCalling": true,
    "description": "Our most powerful open-weight model, which fits into a single H100 GPU (117B parameters with 5.1B active parameters). It has a permissive Apache 2.0 license, configurable reasoning effort, full chain-of-thought access, fine-tunability, and agentic capabilities.",
    "category": "gpt-oss"
  },
  {
    "name": "gpt-oss-20b",
    "provider": "OpenAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.1,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": 0.5,
    "vision": false,
    "functionCalling": true,
    "description": "Our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters). It has a permissive Apache 2.0 license, configurable reasoning effort, full chain-of-thought access, fine-tunability, and agentic capabilities.",
    "category": "gpt-oss"
  },
  {
    "name": "text-embedding-3-large",
    "provider": "OpenAI",
    "contextWindow": 8191,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.13,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": false,
    "functionCalling": false,
    "description": "Our most capable embedding model for both English and non-English tasks. Embeddings are numerical representations of text that can be used to measure the relatedness between two pieces of text. This model is useful for applications such as search, clustering, and recommendations.",
    "category": "text-embedding"
  },
  {
    "name": "text-embedding-3-small",
    "provider": "OpenAI",
    "contextWindow": 8191,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.02,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": false,
    "functionCalling": false,
    "description": "An improved and more performant version of the ada embedding model. Embeddings are numerical representations of text useful for tasks like search, clustering, recommendations, and classification.",
    "category": "text-embedding"
  },
  {
    "name": "text-embedding-ada-002",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.1,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": false,
    "functionCalling": false,
    "description": "An older embedding model. Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. It is used for tasks like search, clustering, and recommendations.",
    "category": "text-embedding"
  },
  {
    "name": "text-moderation",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.0,
    "cachedInputCostPer1M": 0.0,
    "outputCostPer1M": 0.0,
    "vision": false,
    "functionCalling": false,
    "description": "A free, text-only moderation model designed to detect harmful content. It is a previous-generation model, and newer, multimodal 'omni-moderation' models are recommended as the best default moving forward.",
    "category": "moderation"
  },
  {
    "name": "text-moderation-stable",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.0,
    "cachedInputCostPer1M": 0.0,
    "outputCostPer1M": 0.0,
    "vision": false,
    "functionCalling": false,
    "description": "A free, text-only moderation model designed to detect harmful content. It is a previous-generation model, and newer, multimodal 'omni-moderation' models are recommended as the best default moving forward.",
    "category": "moderation"
  },
  {
    "name": "TTS-1",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 15.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": false,
    "functionCalling": false,
    "description": "A text-to-speech model optimized for speed and real-time use cases. It converts text into natural-sounding spoken audio.",
    "category": "speech-generation"
  },
  {
    "name": "TTS-1 HD",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 30.0,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": false,
    "functionCalling": false,
    "description": "A text-to-speech model optimized for high-quality audio output. It converts text to natural-sounding spoken audio and is accessed through the Speech endpoint in the Audio API.",
    "category": "speech-generation"
  },
  {
    "name": "Whisper",
    "provider": "OpenAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "outputCostPer1M": null,
    "pricingPerUse": {
      "transcription": 0.006
    },
    "vision": false,
    "functionCalling": false,
    "description": "A general-purpose speech recognition model trained on a large dataset of diverse audio. It is a multitask model that can perform multilingual speech recognition, speech translation, and language identification. It is optimized for converting spoken language into written text.",
    "category": "transcription"
  },
  {
    "name": "Claude Opus 4.1",
    "provider": "Anthropic",
    "description": "Our most capable and intelligent model yet. Claude Opus 4.1 sets new standards in complex reasoning and advanced coding.",
    "contextWindow": 200000,
    "maxOutputTokens": 32000,
    "inputCostPer1M": 15.0,
    "outputCostPer1M": 75.0,
    "cachedInputCostPer1M": 1.5,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "March 2025"
  },
  {
    "name": "Claude Opus 4",
    "provider": "Anthropic",
    "description": "Previous-generation flagship model with high intelligence and capability.",
    "contextWindow": 200000,
    "maxOutputTokens": 32000,
    "inputCostPer1M": 15.0,
    "outputCostPer1M": 75.0,
    "cachedInputCostPer1M": 1.5,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "March 2025"
  },
  {
    "name": "Claude Sonnet 4",
    "provider": "Anthropic",
    "description": "High-performance model with exceptional reasoning and efficiency. Supports a 1M token context window in beta.",
    "contextWindow": 200000,
    "contextWindowBeta": 1000000,
    "maxOutputTokens": 64000,
    "inputCostPer1M": 3.0,
    "outputCostPer1M": 15.0,
    "cachedInputCostPer1M": 0.3,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "March 2025"
  },
  {
    "name": "Claude Sonnet 3.7",
    "provider": "Anthropic",
    "description": "High-performance model with early extended thinking. Supports up to 128k output tokens in beta.",
    "contextWindow": 200000,
    "maxOutputTokens": 64000,
    "maxOutputTokensBeta": 128000,
    "inputCostPer1M": 3.0,
    "outputCostPer1M": 15.0,
    "cachedInputCostPer1M": 0.3,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "October 2024"
  },
  {
    "name": "Claude Sonnet 3.5",
    "provider": "Anthropic",
    "description": "Deprecated model with high intelligence and early extended thinking capabilities.",
    "contextWindow": 200000,
    "maxOutputTokens": 64000,
    "inputCostPer1M": 3.0,
    "outputCostPer1M": 15.0,
    "cachedInputCostPer1M": 0.3,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "October 2024"
  },
  {
    "name": "Claude Haiku 3.5",
    "provider": "Anthropic",
    "description": "Our fastest model with intelligence at blazing speeds.",
    "contextWindow": 200000,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 0.8,
    "outputCostPer1M": 4.0,
    "cachedInputCostPer1M": 0.08,
    "vision": true,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "July 2024"
  },
  {
    "name": "Claude Opus 3",
    "provider": "Anthropic",
    "description": "Deprecated flagship model from the Opus family with high intelligence and capability.",
    "contextWindow": 200000,
    "maxOutputTokens": 32000,
    "inputCostPer1M": 15.0,
    "outputCostPer1M": 75.0,
    "cachedInputCostPer1M": 1.5,
    "vision": true,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": "March 2025"
  },
  {
    "name": "Claude Haiku 3",
    "provider": "Anthropic",
    "description": "A fast and compact model for near-instant responsiveness.",
    "contextWindow": 200000,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 0.25,
    "outputCostPer1M": 1.25,
    "cachedInputCostPer1M": 0.03,
    "vision": true,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "August 2023"
  },
  {
    "name": "Groq Compound",
    "provider": "Groq",
    "description": "AI system powered by openly available models with built-in tools for web search and code execution.",
    "contextWindow": 131072,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": null,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": null
  },
  {
    "name": "Groq Compound Mini",
    "provider": "Groq",
    "description": "Mini version of Groq Compound for evaluation purposes.",
    "contextWindow": 131072,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": null,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": null
  },
  {
    "name": "llama-3.1-8b-instant",
    "provider": "Groq",
    "description": "Production model from Meta LLaMA 3.1 series.",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.05,
    "outputCostPer1M": 0.08,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "2023-12"
  },
  {
    "name": "llama-3.3-70b-versatile",
    "provider": "Groq",
    "description": "Production model from Meta LLaMA 3.3 series.",
    "contextWindow": 131072,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.59,
    "outputCostPer1M": 0.79,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "2023-12"
  },
  {
    "name": "meta-llama/llama-guard-4-12b",
    "provider": "Groq",
    "description": "Guard model from Meta LLaMA 4 series.",
    "contextWindow": 131072,
    "maxOutputTokens": 1024,
    "maxFileSize": 20,
    "inputCostPer1M": 0.2,
    "outputCostPer1M": 0.2,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": false,
    "extendedThinking": false,
    "knowledgeCutoff": "2024-08"
  },
  {
    "name": "openai/gpt-oss-120b",
    "provider": "Groq",
    "description": "Open-weight 120B parameter GPT model with reasoning, search, and code execution.",
    "contextWindow": 131072,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 0.15,
    "outputCostPer1M": 0.75,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": null
  },
  {
    "name": "openai/gpt-oss-20b",
    "provider": "Groq",
    "description": "Open-weight 20B parameter GPT model with reasoning and code execution.",
    "contextWindow": 131072,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 0.1,
    "outputCostPer1M": 0.5,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": null
  },
  {
    "name": "whisper-large-v3",
    "provider": "Groq",
    "description": "Large OpenAI Whisper model for speech-to-text.",
    "contextWindow": null,
    "maxOutputTokens": null,
    "maxFileSize": 100,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": null
  },
  {
    "name": "whisper-large-v3-turbo",
    "provider": "Groq",
    "description": "Turbo version of Whisper-large-v3 for faster speech-to-text.",
    "contextWindow": null,
    "maxOutputTokens": null,
    "maxFileSize": 100,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": null
  },
  {
    "name": "meta-llama/llama-4-maverick-17b-128e-instruct",
    "provider": "Groq",
    "description": "Preview instruct model from Meta LLaMA 4 series.",
    "contextWindow": 131072,
    "maxOutputTokens": 8192,
    "maxFileSize": 20,
    "inputCostPer1M": 0.2,
    "outputCostPer1M": 0.6,
    "cachedInputCostPer1M": null,
    "vision": true,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "2024-08"
  },
  {
    "name": "meta-llama/llama-4-scout-17b-16e-instruct",
    "provider": "Groq",
    "description": "Preview instruct model from Meta LLaMA 4 series.",
    "contextWindow": 131072,
    "maxOutputTokens": 8192,
    "maxFileSize": 20,
    "inputCostPer1M": 0.11,
    "outputCostPer1M": 0.34,
    "cachedInputCostPer1M": null,
    "vision": true,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "2024-08"
  },
  {
    "name": "meta-llama/llama-prompt-guard-2-22m",
    "provider": "Groq",
    "description": "Prompt guard model from Meta LLaMA 2 series.",
    "contextWindow": 512,
    "maxOutputTokens": 512,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": false,
    "extendedThinking": false,
    "knowledgeCutoff": "2022-09"
  },
  {
    "name": "meta-llama/llama-prompt-guard-2-86m",
    "provider": "Groq",
    "description": "Prompt guard model from Meta LLaMA 2 series.",
    "contextWindow": 512,
    "maxOutputTokens": 512,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": false,
    "extendedThinking": false,
    "knowledgeCutoff": "2022-09"
  },
  {
    "name": "moonshotai/kimi-k2-instruct",
    "provider": "Groq",
    "description": "Instruct model from Moonshot AI for general tasks.",
    "contextWindow": 131072,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 1.0,
    "outputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.5,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": null
  },
  {
    "name": "moonshotai/kimi-k2-instruct-0905",
    "provider": "Groq",
    "description": "Updated Kimi K2 instruct model from Moonshot AI.",
    "contextWindow": 262144,
    "maxOutputTokens": 16384,
    "inputCostPer1M": 1.0,
    "outputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.5,
    "vision": false,
    "multilingual": true,
    "extendedThinking": false,
    "knowledgeCutoff": "2025-09"
  },
  {
    "name": "playai-tts",
    "provider": "Groq",
    "description": "Text-to-speech model from PlayAI.",
    "contextWindow": 8192,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": false,
    "extendedThinking": false,
    "knowledgeCutoff": null
  },
  {
    "name": "playai-tts-arabic",
    "provider": "Groq",
    "description": "Arabic text-to-speech model from PlayAI.",
    "contextWindow": 8192,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": false,
    "extendedThinking": false,
    "knowledgeCutoff": null
  },
  {
    "name": "qwen/qwen3-32b",
    "provider": "Groq",
    "description": "Large 32B parameter Qwen3 model for high-performance tasks.",
    "contextWindow": 131072,
    "maxOutputTokens": 40960,
    "inputCostPer1M": 0.29,
    "outputCostPer1M": 0.59,
    "cachedInputCostPer1M": null,
    "vision": false,
    "multilingual": true,
    "extendedThinking": true,
    "knowledgeCutoff": null
  },
  {
    "name": "Gemini 2.5 Pro",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 1.25,
    "inputCostPer1M_large": 2.5,
    "cachedInputCostPer1M": 0.31,
    "cachedInputCostPer1M_large": 0.625,
    "outputCostPer1M": 10.0,
    "outputCostPer1M_large": 15.0,
    "contextCachingStoragePer1M": 4.5,
    "batchInputCostPer1M": 0.625,
    "batchInputCostPer1M_large": 1.25,
    "batchOutputCostPer1M": 5.0,
    "batchOutputCostPer1M_large": 7.5,
    "vision": true,
    "functionCalling": true,
    "description": "Our state-of-the-art multipurpose model, which excels at coding and complex reasoning tasks.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "January 2025",
    "supportedDataTypes": ["audio", "images", "video", "text", "pdf"]
  },
  {
    "name": "Gemini 2.5 Flash",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 0.3,
    "inputCostPer1M_audio": 1.0,
    "outputCostPer1M": 2.5,
    "cachedInputCostPer1M": 0.075,
    "cachedInputCostPer1M_audio": 0.25,
    "contextCachingStoragePer1M": 1.0,
    "batchInputCostPer1M": 0.15,
    "batchInputCostPer1M_audio": 0.5,
    "batchOutputCostPer1M": 1.25,
    "liveAPIInputCostText": 0.5,
    "liveAPIInputCostAudio": 3.0,
    "liveAPIOutputCostText": 2.0,
    "liveAPIOutputCostAudio": 12.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our first hybrid reasoning model which supports a 1M token context window and has thinking budgets.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "January 2025",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Gemini 2.5 Flash-Lite",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 65536,
    "inputCostPer1M": 0.1,
    "inputCostPer1M_audio": 0.3,
    "outputCostPer1M": 0.4,
    "cachedInputCostPer1M": 0.025,
    "cachedInputCostPer1M_audio": 0.125,
    "contextCachingStoragePer1M": 1.0,
    "batchInputCostPer1M": 0.05,
    "batchInputCostPer1M_audio": 0.15,
    "batchOutputCostPer1M": 0.2,
    "vision": true,
    "functionCalling": true,
    "description": "Our smallest and most cost effective model, built for at scale usage.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "January 2025",
    "supportedDataTypes": ["text", "image", "video", "audio", "pdf"]
  },
  {
    "name": "Gemini 2.5 Flash Native Audio",
    "provider": "Google",
    "contextWindow": 128000,
    "maxOutputTokens": 8000,
    "inputCostPer1M_text": 0.5,
    "inputCostPer1M_audio": 3.0,
    "outputCostPer1M_text": 2.0,
    "outputCostPer1M_audio": 12.0,
    "vision": false,
    "functionCalling": true,
    "description": "Our native audio models optimized for higher quality audio outputs with better pacing, voice naturalness, verbosity, and mood.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "January 2025",
    "supportedDataTypes": ["audio", "video", "text"]
  },
  {
    "name": "Gemini 2.5 Flash Image Preview",
    "provider": "Google",
    "contextWindow": 32768,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 0.3,
    "outputCostPer1M": null,
    "outputCostPerImage": 0.039,
    "batchInputCostPer1M": 0.15,
    "batchOutputCostPerImage": 0.0195,
    "vision": true,
    "functionCalling": false,
    "description": "Our native image generation model, optimized for speed, flexibility, and contextual understanding.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "June 2025",
    "supportedDataTypes": ["images", "text"]
  },
  {
    "name": "Gemini 2.5 Flash Preview TTS",
    "provider": "Google",
    "contextWindow": 8000,
    "maxOutputTokens": 16000,
    "inputCostPer1M": 0.5,
    "outputCostPer1M": 10.0,
    "batchInputCostPer1M": 0.25,
    "batchOutputCostPer1M": 5.0,
    "vision": false,
    "functionCalling": false,
    "description": "Our 2.5 Flash text-to-speech audio model optimized for price-performant, low-latency, controllable speech generation.",
    "category": "gemini-2.5",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Gemini 2.5 Pro Preview TTS",
    "provider": "Google",
    "contextWindow": 8000,
    "maxOutputTokens": 16000,
    "inputCostPer1M": 1.0,
    "outputCostPer1M": 20.0,
    "batchInputCostPer1M": 0.5,
    "batchOutputCostPer1M": 10.0,
    "vision": false,
    "functionCalling": false,
    "description": "Our 2.5 Pro text-to-speech audio model optimized for powerful, low-latency speech generation for more natural outputs and easier to steer prompts.",
    "category": "gemini-2.5",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Gemini 2.0 Flash",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 0.1,
    "inputCostPer1M_audio": 0.7,
    "outputCostPer1M": 0.4,
    "cachedInputCostPer1M": 0.025,
    "cachedInputCostPer1M_audio": 0.175,
    "contextCachingStoragePer1M": 1.0,
    "imageGenerationCostPerImage": 0.039,
    "batchInputCostPer1M": 0.05,
    "batchInputCostPer1M_audio": 0.35,
    "batchOutputCostPer1M": 0.2,
    "batchImageGenerationCostPerImage": 0.0195,
    "liveAPIInputCostText": 0.35,
    "liveAPIInputCostAudio": 2.1,
    "liveAPIOutputCostText": 1.5,
    "liveAPIOutputCostAudio": 8.5,
    "vision": true,
    "functionCalling": true,
    "description": "Our most balanced multimodal model with great performance across all tasks, with a 1 million token context window, and built for the era of Agents.",
    "category": "gemini-2.0",
    "knowledgeCutoff": "August 2024",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Gemini 2.0 Flash-Lite",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 0.075,
    "outputCostPer1M": 0.3,
    "batchInputCostPer1M": 0.0375,
    "batchOutputCostPer1M": 0.15,
    "vision": true,
    "functionCalling": true,
    "description": "Our smallest and most cost effective model, built for at scale usage.",
    "category": "gemini-2.0",
    "knowledgeCutoff": "August 2024",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Gemini 1.5 Flash",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 0.075,
    "inputCostPer1M_large": 0.15,
    "outputCostPer1M": 0.3,
    "outputCostPer1M_large": 0.6,
    "cachedInputCostPer1M": 0.01875,
    "cachedInputCostPer1M_large": 0.0375,
    "contextCachingStoragePer1M": 1.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our fastest multimodal model with great performance for diverse, repetitive tasks and a 1 million token context window.",
    "category": "gemini-1.5",
    "deprecationDate": "September 2025",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Gemini 1.5 Flash-8B",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 0.0375,
    "inputCostPer1M_large": 0.075,
    "outputCostPer1M": 0.15,
    "outputCostPer1M_large": 0.3,
    "cachedInputCostPer1M": 0.01,
    "cachedInputCostPer1M_large": 0.02,
    "contextCachingStoragePer1M": 0.25,
    "vision": true,
    "functionCalling": true,
    "description": "Our smallest model for lower intelligence use cases, with a 1 million token context window.",
    "category": "gemini-1.5",
    "deprecationDate": "September 2025",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Gemini 1.5 Pro",
    "provider": "Google",
    "contextWindow": 2097152,
    "maxOutputTokens": 8192,
    "inputCostPer1M": 1.25,
    "inputCostPer1M_large": 2.5,
    "outputCostPer1M": 5.0,
    "outputCostPer1M_large": 10.0,
    "cachedInputCostPer1M": 0.3125,
    "cachedInputCostPer1M_large": 0.625,
    "contextCachingStoragePer1M": 4.5,
    "vision": true,
    "functionCalling": true,
    "description": "Our highest intelligence Gemini 1.5 series model, with a breakthrough 2 million token context window.",
    "category": "gemini-1.5",
    "deprecationDate": "September 2025",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Imagen 4 Fast",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerImage": 0.02,
    "vision": false,
    "functionCalling": false,
    "description": "Our latest image generation model, with significantly better text rendering and better overall image quality.",
    "category": "image-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Imagen 4 Standard",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerImage": 0.04,
    "vision": false,
    "functionCalling": false,
    "description": "Our latest image generation model, with significantly better text rendering and better overall image quality.",
    "category": "image-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Imagen 4 Ultra",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerImage": 0.06,
    "vision": false,
    "functionCalling": false,
    "description": "Our latest image generation model, with significantly better text rendering and better overall image quality.",
    "category": "image-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Imagen 3",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerImage": 0.03,
    "vision": false,
    "functionCalling": false,
    "description": "Our state-of-the-art image generation model, available to developers on the paid tier of the Gemini API.",
    "category": "image-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Veo 3",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerSecond": 0.4,
    "vision": false,
    "functionCalling": false,
    "description": "Our latest video generation model, available to developers on the paid tier of the Gemini API.",
    "category": "video-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Veo 3 Fast",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerSecond": 0.15,
    "vision": false,
    "functionCalling": false,
    "description": "A faster, more accessible version of Veo 3, optimized for speed and business use cases. Available to developers on the paid tier of the Gemini API.",
    "category": "video-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Veo 2",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerSecond": 0.35,
    "vision": false,
    "functionCalling": false,
    "description": "Our state-of-the-art video generation model, available to developers on the paid tier of the Gemini API.",
    "category": "video-generation",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Gemini Embedding",
    "provider": "Google",
    "contextWindow": 2048,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.15,
    "outputCostPer1M": null,
    "batchInputCostPer1M": 0.075,
    "vision": false,
    "functionCalling": false,
    "description": "Our newest embeddings model, more stable and with higher rate limits than previous versions, available to developers on the free and paid tiers of the Gemini API.",
    "category": "text-embedding",
    "supportedDataTypes": ["text"],
    "outputDimensions": "Flexible, supports: 128 - 3072, Recommended: 768, 1536, 3072"
  },
  {
    "name": "Gemma 3",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.0,
    "outputCostPer1M": 0.0,
    "vision": false,
    "functionCalling": true,
    "description": "Our lightweight, state-of the art, open model built from the same technology that powers our Gemini models.",
    "category": "open-source",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Gemma 3n",
    "provider": "Google",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": 0.0,
    "outputCostPer1M": 0.0,
    "vision": false,
    "functionCalling": true,
    "description": "Our open model built for efficient performance on everyday devices like mobile phones, laptops, and tablets.",
    "category": "open-source",
    "supportedDataTypes": ["text"]
  },
  {
    "name": "Gemini 2.5 Flash Live",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": true,
    "functionCalling": true,
    "description": "The Gemini 2.5 Flash Live model works with the Live API to enable low-latency bidirectional voice and video interactions with Gemini.",
    "category": "gemini-2.5",
    "knowledgeCutoff": "January 2025",
    "supportedDataTypes": ["audio", "video", "text"]
  },
  {
    "name": "Gemini 2.0 Flash Live",
    "provider": "Google",
    "contextWindow": 1048576,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": true,
    "functionCalling": true,
    "description": "The Gemini 2.0 Flash Live model works with the Live API to enable low-latency bidirectional voice and video interactions with Gemini.",
    "category": "gemini-2.0",
    "knowledgeCutoff": "August 2024",
    "supportedDataTypes": ["audio", "video", "text"]
  },
  {
    "name": "Gemini 2.0 Flash Preview Image Generation",
    "provider": "Google",
    "contextWindow": 32000,
    "maxOutputTokens": 8192,
    "inputCostPer1M": null,
    "outputCostPer1M": null,
    "vision": true,
    "functionCalling": false,
    "description": "Gemini 2.0 Flash Preview Image Generation delivers improved image generation features, including generating and editing images conversationally.",
    "category": "gemini-2.0",
    "knowledgeCutoff": "August 2024",
    "supportedDataTypes": ["audio", "images", "video", "text"]
  },
  {
    "name": "Grok 4",
    "provider": "xAI",
    "contextWindow": 256000,
    "maxOutputTokens": 256000,
    "inputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.75,
    "outputCostPer1M": 15.0,
    "vision": true,
    "functionCalling": true,
    "description": "Our most advanced reasoning model with native tool use and real-time search integration. Features a 256k token context window and built for complex problem solving.",
    "category": "grok-4",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text", "image"],
    "aliases": ["grok-4-0709", "grok-4-latest"],
    "rateLimits": {
      "requestsPerMinute": 480,
      "tokensPerMinute": 2000000
    },
    "features": [
      "reasoning",
      "structured_outputs",
      "function_calling",
      "tool_use",
      "live_search"
    ]
  },
  {
    "name": "Grok 3",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.75,
    "outputCostPer1M": 15.0,
    "vision": false,
    "functionCalling": true,
    "description": "High-performance model excelling at data extraction, coding, and summarization. A flagship model with strong reasoning capabilities.",
    "category": "grok-3",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "aliases": ["grok-3-latest"],
    "rateLimits": {
      "requestsPerMinute": 600,
      "tokensPerMinute": null
    },
    "features": ["structured_outputs", "function_calling"]
  },
  {
    "name": "Grok 3 Mini",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.3,
    "cachedInputCostPer1M": 0.075,
    "outputCostPer1M": 0.5,
    "vision": false,
    "functionCalling": true,
    "description": "Lightweight, cost-effective model for simpler tasks. Shows thinking traces and provides good performance at a lower cost.",
    "category": "grok-3",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "aliases": ["grok-3-mini-latest"],
    "rateLimits": {
      "requestsPerMinute": 480,
      "tokensPerMinute": null
    },
    "features": ["structured_outputs", "function_calling", "thinking_traces"]
  },
  {
    "name": "Grok 3 Fast (US East)",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.75,
    "outputCostPer1M": 15.0,
    "vision": false,
    "functionCalling": true,
    "description": "Faster Grok 3 with identical quality for time-sensitive tasks. Optimized for low latency in US East region.",
    "category": "grok-3",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "region": "us-east-1",
    "rateLimits": {
      "requestsPerMinute": 600,
      "tokensPerMinute": null
    },
    "features": ["low_latency", "structured_outputs", "function_calling"]
  },
  {
    "name": "Grok 3 Fast (EU West)",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 3.0,
    "cachedInputCostPer1M": 0.75,
    "outputCostPer1M": 15.0,
    "vision": false,
    "functionCalling": true,
    "description": "Faster Grok 3 with identical quality for time-sensitive tasks. Optimized for low latency in EU West region.",
    "category": "grok-3",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "region": "eu-west-1",
    "rateLimits": {
      "requestsPerMinute": 600,
      "tokensPerMinute": null
    },
    "features": ["low_latency", "structured_outputs", "function_calling"]
  },
  {
    "name": "Grok 3 Mini Fast",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.3,
    "cachedInputCostPer1M": 0.075,
    "outputCostPer1M": 0.5,
    "vision": false,
    "functionCalling": true,
    "description": "Fast, lightweight model for cost-effective, time-sensitive tasks. Combines speed with affordability.",
    "category": "grok-3",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "rateLimits": {
      "requestsPerMinute": 180,
      "tokensPerMinute": null
    },
    "features": [
      "low_latency",
      "cost_effective",
      "structured_outputs",
      "function_calling"
    ]
  },
  {
    "name": "Grok 2 Vision (US East)",
    "provider": "xAI",
    "contextWindow": 32768,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 5.0,
    "cachedInputCostPer1M": 1.25,
    "outputCostPer1M": 15.0,
    "vision": true,
    "functionCalling": true,
    "description": "Multimodal model supporting both text and image inputs with vision capabilities.",
    "category": "grok-2",
    "knowledgeCutoff": "December 2024",
    "supportedDataTypes": ["text", "image"],
    "region": "us-east-1",
    "aliases": ["grok-2-vision-1212"],
    "rateLimits": {
      "requestsPerMinute": 600,
      "tokensPerMinute": null
    },
    "features": [
      "vision",
      "multimodal",
      "structured_outputs",
      "function_calling"
    ],
    "imageConstraints": {
      "maxSize": "20MiB",
      "supportedFormats": ["jpg", "jpeg", "png"],
      "maxImages": "unlimited"
    }
  },
  {
    "name": "Grok 2 Vision (EU West)",
    "provider": "xAI",
    "contextWindow": 32768,
    "maxOutputTokens": 32768,
    "inputCostPer1M": 5.0,
    "cachedInputCostPer1M": 1.25,
    "outputCostPer1M": 15.0,
    "vision": true,
    "functionCalling": true,
    "description": "Multimodal model supporting both text and image inputs with vision capabilities.",
    "category": "grok-2",
    "knowledgeCutoff": "December 2024",
    "supportedDataTypes": ["text", "image"],
    "region": "eu-west-1",
    "aliases": ["grok-2-vision-1212"],
    "rateLimits": {
      "requestsPerMinute": 50,
      "tokensPerMinute": null
    },
    "features": [
      "vision",
      "multimodal",
      "structured_outputs",
      "function_calling"
    ],
    "imageConstraints": {
      "maxSize": "20MiB",
      "supportedFormats": ["jpg", "jpeg", "png"],
      "maxImages": "unlimited"
    }
  },
  {
    "name": "Grok 2 Image Generation",
    "provider": "xAI",
    "contextWindow": null,
    "maxOutputTokens": null,
    "inputCostPer1M": null,
    "outputCostPerImage": 0.07,
    "vision": false,
    "functionCalling": false,
    "description": "Image generation model that creates images from text descriptions.",
    "category": "image-generation",
    "knowledgeCutoff": "December 2024",
    "supportedDataTypes": ["text"],
    "aliases": ["grok-2-image-1212"],
    "rateLimits": {
      "requestsPerMinute": 300,
      "tokensPerMinute": null
    },
    "features": ["image_generation", "text_to_image"]
  },
  {
    "name": "Grok Code Fast",
    "provider": "xAI",
    "contextWindow": 131072,
    "maxOutputTokens": 131072,
    "inputCostPer1M": 0.2,
    "cachedInputCostPer1M": 0.05,
    "outputCostPer1M": 1.5,
    "vision": false,
    "functionCalling": true,
    "description": "Specialized coding model optimized for programming tasks and code generation.",
    "category": "grok-code",
    "knowledgeCutoff": "November 2024",
    "supportedDataTypes": ["text"],
    "aliases": ["grok-code-fast-1"],
    "rateLimits": {
      "requestsPerMinute": 600,
      "tokensPerMinute": null
    },
    "features": [
      "code_generation",
      "programming",
      "structured_outputs",
      "function_calling"
    ]
  }
]
