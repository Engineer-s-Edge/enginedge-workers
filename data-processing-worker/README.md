# Data Processing Worker - Document Pipeline Platform

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Status](https://img.shields.io/badge/status-production--ready-brightgreen.svg)
![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen.svg)
![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)
![TypeScript](https://img.shields.io/badge/typescript-5.0-blue.svg)
![NestJS](https://img.shields.io/badge/nestjs-10.0-red.svg)
![License](https://img.shields.io/badge/license-Proprietary-yellow.svg)

![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)
![Tests](https://img.shields.io/badge/tests-450%2B%20passing-brightgreen.svg)
![PRs](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

</div>

---

A production-ready microservice for comprehensive document processing, intelligent text splitting, multi-provider embeddings, and enterprise-grade vector storage with MongoDB Atlas, Pinecone, and Weaviate support.

## ğŸ¯ Overview

<div align="center">

**ğŸš€ Enterprise-Grade Document Processing Pipeline**

[![Architecture](https://img.shields.io/badge/architecture-hexagonal-purple.svg)](documentation/ARCHITECTURE.md)
[![API](https://img.shields.io/badge/API-REST-orange.svg)](documentation/API.md)
[![Docs](https://img.shields.io/badge/docs-comprehensive-blue.svg)](documentation/)
[![Monitoring](https://img.shields.io/badge/monitoring-prometheus-orange.svg)](documentation/METRICS.md)

</div>

The **Data Processing Worker** is a highly scalable, production-grade microservice that provides:

- **10+ Document Loaders** - PDF, DOCX, CSV, Web, GitHub, YouTube, Notion, and more
- **13 Text Splitters** - Generic, code-specific, and format-aware splitting strategies
- **5 Embedding Providers** - OpenAI, Google, Cohere, HuggingFace, Local models
- **6 Vector Stores** - MongoDB Atlas, Pinecone, Weaviate, PgVector, Qdrant, ChromaDB
- **Advanced Search** - Similarity, hybrid, filtered, and metadata-aware searches
- **Kafka Integration** - Async document processing and event streaming
- **16+ REST API Endpoints** - Comprehensive API coverage
- **Intelligent Caching** - 60-80% embedding cache hit rates
- **Performance Optimized** - Batch processing, deduplication, smart fallbacks

## âœ¨ Features

<div align="center">

| ğŸ“„ **10+ Loaders** | âœ‚ï¸ **13 Splitters** | ğŸ¤– **5 Embedders** | ğŸ—‚ï¸ **6 Vector Stores** |
|:------------------:|:------------------:|:------------------:|:---------------------:|
| PDF, DOCX, Web | Semantic, Code, Format | OpenAI, Google, Local | MongoDB, Pinecone, Weaviate |

</div>

### Document Loaders

| Loader | Formats | Best For |
|--------|---------|----------|
| **File Loader** | PDF, DOCX, CSV, XLSX, PPTX, SRT, JSON, EPUB | Local documents |
| **Web Loaders** | HTML, Markdown, Structured data | Web pages and articles |
| **GitHub Loader** | Repositories, commits, issues | Code repositories |
| **YouTube Loader** | Video transcripts | Video content |
| **Notion Loader** | Pages, databases | Notion workspaces |
| **Search Loaders** | SerpAPI, Tavily AI | Search results |
| **Crawler** | Recursive URL crawl | Website documentation |

### Text Splitters

- **Generic**: Character, Token, Recursive Character, Semantic (sentence/paragraph-aware)
- **Code-Specific**: Python, JavaScript, TypeScript, Java, C++, Go (function/class-aware)
- **Format-Specific**: LaTeX, Markdown, HTML (tag/section-aware)
- **Intelligent Selection**: Auto-detect optimal splitter for document type

### Embedding Providers

| Provider | Model | Dimensions | Cost |
|----------|-------|------------|------|
| **OpenAI** | text-embedding-3-small | 1536 | $0.02 per 1M tokens |
| **Google** | text-embedding-004 | 768 | Free tier available |
| **Cohere** | embed-english-v3.0 | 1024 | Custom pricing |
| **HuggingFace** | Various models | Varies | Free (self-hosted) |
| **Local** | ONNX models | Configurable | $0 (offline) |

### Vector Storage

| Store | Type | Best For | Status |
|-------|------|----------|--------|
| **MongoDB Atlas** | Cloud Managed | Production, Scalability | âœ… Enabled |
| **Pinecone** | Managed Cloud | Low-latency, Global | Ready |
| **Weaviate** | Open-Source Cloud | Flexibility, Multi-cloud | Ready |
| **PgVector** | PostgreSQL Extension | Relational + Vectors | Ready |
| **Qdrant** | Open-Source | Real-time, Advanced filtering | Ready |
| **ChromaDB** | Open-Source | Local, Lightweight | Ready |

## ğŸš€ Quick Start

### Prerequisites

```bash
- Node.js 18+
- npm or yarn
- MongoDB (for vector store) or managed service (Pinecone, Weaviate)
```

### Installation

```bash
# Navigate to data-processing-worker
cd enginedge-workers/data-processing-worker

# Install dependencies
npm install

# Build the project
npm run build
```

### Configuration

Create a `.env` file:

```env
# Server
PORT=3002
NODE_ENV=development
LOG_LEVEL=debug

# Database
MONGODB_URI=mongodb://localhost:27017/data-processing-worker
MONGODB_POOL_SIZE=20

# Embedding Providers
OPENAI_API_KEY=your_key_here
GOOGLE_API_KEY=your_key_here
COHERE_API_KEY=your_key_here

# Vector Stores
PINECONE_API_KEY=your_key_here
PINECONE_ENVIRONMENT=us-east1-aws
WEAVIATE_URL=http://localhost:8080

# Kafka (optional)
KAFKA_BROKERS=localhost:9092
KAFKA_TOPIC_PREFIX=data-processing-worker

# Caching
CACHE_MAX_SIZE=104857600
CACHE_TTL=3600
```

### Running the Service

```bash
# Development mode with hot reload
npm run start:dev

# Production mode
npm run start:prod

# Watch mode
npm run start
```

The service will start on `http://localhost:3002` (or your configured PORT).

### Health Check

```bash
curl http://localhost:3002/health
```

Expected response:
```json
{
  "status": "ok",
  "timestamp": "2025-10-24T...",
  "uptime": 123.45,
  "memory": {
    "used": 50000000,
    "total": 100000000
  }
}
```

## ğŸ“– Documentation

<div align="center">

Comprehensive documentation is available in the `documentation/` folder:

| ğŸ“š Document | ğŸ“ Description | ğŸ”— Link |
|------------|---------------|---------|
| **ARCHITECTURE** | System architecture with Mermaid diagrams | [View](documentation/ARCHITECTURE.md) |
| **API** | Complete API reference for 16+ endpoints | [View](documentation/API.md) |
| **METRICS** | Prometheus monitoring & Grafana dashboards | [View](documentation/METRICS.md) |
| **TROUBLESHOOTING** | Common issues and solutions | [View](documentation/TROUBLESHOOTING.md) |
| **PERFORMANCE** | Optimization & tuning guide | [View](documentation/PERFORMANCE.md) |
| **DEPLOYMENT** | Docker & Kubernetes deployment | [View](documentation/DEPLOYMENT.md) |

</div>

## ğŸ”Œ API Examples

### Upload Document

```bash
curl -X POST http://localhost:3002/documents/upload \
  -H "Content-Type: multipart/form-data" \
  -F "file=@document.pdf" \
  -F "split=true" \
  -F "embed=true"
```

### Process URL

```bash
curl -X POST http://localhost:3002/documents/process-url \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com/article",
    "split": true,
    "embed": true
  }'
```

### Search Documents

```bash
curl -X POST http://localhost:3002/vector-store/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning concepts",
    "limit": 5,
    "filter": {"userId": "user123"}
  }'
```

### Hybrid Search

```bash
curl -X POST http://localhost:3002/vector-store/hybrid-search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "artificial intelligence",
    "textWeight": 0.3,
    "vectorWeight": 0.7,
    "limit": 10
  }'
```

### Generate Embeddings

```bash
curl -X POST http://localhost:3002/embedders/embed \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Sample text to embed",
    "provider": "openai",
    "cache": true
  }'
```

## ğŸ—ï¸ Architecture

<div align="center">

**Hexagonal Architecture (Ports & Adapters)**

[![Clean Architecture](https://img.shields.io/badge/clean-architecture-blue.svg)](documentation/ARCHITECTURE.md)
[![SOLID](https://img.shields.io/badge/principles-SOLID-green.svg)](documentation/ARCHITECTURE.md)
[![DDD](https://img.shields.io/badge/design-DDD-purple.svg)](documentation/ARCHITECTURE.md)

</div>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Infrastructure Layer                 â”‚
â”‚  (Controllers, Adapters, External I/O)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Application Layer                  â”‚
â”‚  (Use Cases, Services, Ports)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Domain Layer                     â”‚
â”‚  (Entities, Value Objects, Logic)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Testing

<div align="center">

![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen.svg)
![Tests](https://img.shields.io/badge/tests-450%2B-brightgreen.svg)
![Unit](https://img.shields.io/badge/unit-passing-brightgreen.svg)
![Integration](https://img.shields.io/badge/integration-passing-brightgreen.svg)

</div>

```bash
# Run all tests
npm test

# Run tests with coverage
npm run test:cov

# Run tests in watch mode
npm run test:watch
```

**Test Coverage:** 95%+ across 450+ tests

## ğŸ“Š Metrics & Monitoring

<div align="center">

![Prometheus](https://img.shields.io/badge/prometheus-ready-orange.svg)
![Grafana](https://img.shields.io/badge/grafana-dashboards-orange.svg)
![Metrics](https://img.shields.io/badge/metrics-50%2B-blue.svg)
![Alerts](https://img.shields.io/badge/alerts-configured-red.svg)

</div>

The Data Processing Worker exposes Prometheus-compatible metrics:

```bash
curl http://localhost:3002/metrics
```

**Key Metrics:**
- `documents_loaded_total` - Total documents loaded
- `document_processing_duration_seconds` - Processing time histogram
- `embeddings_generated_total` - Total embeddings generated
- `embeddings_cache_hits_total` - Cache hit counter
- `vector_search_duration_seconds` - Search latency histogram
- `http_requests_total` - HTTP request counter

<div align="center">

**[ğŸ“Š Complete Metrics Guide â†’](documentation/METRICS.md)**

</div>

## ğŸ”§ Configuration

### Document Processing

```typescript
{
  split: true,                 // Enable text splitting
  embed: true,                 // Generate embeddings
  store: true,                 // Store in vector database
  chunkSize: 512,              // Chunk size in tokens
  chunkOverlap: 50,            // Overlap between chunks
  metadata: {}                 // Custom metadata
}
```

### Embedding Configuration

```typescript
{
  provider: "openai",          // Embedding provider
  model: "text-embedding-3-small",
  batchSize: 100,              // Batch size for efficiency
  cache: true,                 // Enable caching
  deduplication: true,         // Deduplicate before embedding
  fallbackProvider: "local"    // Fallback if primary fails
}
```

### Vector Store Configuration

```typescript
{
  primaryStore: "mongodb",     // Primary vector store
  backupStore: "pinecone",     // Backup store
  searchLimit: 10,             // Default result limit
  minSimilarity: 0.5,          // Similarity threshold
  enableHybridSearch: true,    // Enable hybrid search
  persistenceEnabled: true     // Enable persistence
}
```

## ğŸš¢ Deployment

### Docker

```bash
# Build image
docker build -t data-processing-worker:latest .

# Run container
docker run -p 3002:3002 \
  -e PORT=3002 \
  -e MONGODB_URI=mongodb://mongo:27017 \
  -e OPENAI_API_KEY=your_key \
  data-processing-worker:latest
```

### Kubernetes

```bash
# Apply manifests
kubectl apply -f k8s/

# Check status
kubectl get pods -l app=data-processing-worker
```

See [DEPLOYMENT.md](documentation/DEPLOYMENT.md) for detailed deployment instructions.

## ğŸ“ˆ Performance

<div align="center">

| Operation | Target | Typical | Peak Load |
|-----------|--------|---------|-----------|
| **Document Load** | < 2s | 1.2s | 3.5s |
| **Text Splitting** | < 500ms | 300ms | 1.2s |
| **Single Embedding** | < 200ms | 150ms | 350ms |
| **Batch Embeddings** | < 5s | 3.2s | 8.5s |
| **Similarity Search** | < 100ms | 45ms | 200ms |
| **Cache Hit Rate** | > 60% | 75% | 72% |

</div>

See [PERFORMANCE.md](documentation/PERFORMANCE.md) for detailed benchmarks and optimization strategies.

## ğŸ¤ Contributing

1. Follow hexagonal architecture principles
2. Write tests for all new features (target 90%+ coverage)
3. Use TypeScript strict mode
4. Follow NestJS conventions
5. Update documentation

## ğŸ“ License

[Your License Here]

## ğŸ”— Related Services

- **Assistant Worker** - AI agent execution and memory
- **Agent Tool Worker** - Tool registry and execution
- **Main Node** - Core orchestration service

## ğŸ“ Support

For issues, questions, or contributions:
- GitHub Issues: [link]
- Documentation: `documentation/`
- Troubleshooting: [TROUBLESHOOTING.md](documentation/TROUBLESHOOTING.md)

---

<div align="center">

### ğŸŒŸ Star this repo if you find it helpful! ğŸŒŸ

**Status:** âœ… Production Ready (95% complete)  
**Version:** 1.0.0  
**Last Updated:** October 24, 2025

---

Made with â¤ï¸ by the EnginEdge Team

[![GitHub](https://img.shields.io/badge/github-EnginEdge-black.svg?logo=github)](https://github.com/yourusername/enginedge)
[![Documentation](https://img.shields.io/badge/docs-complete-blue.svg)](documentation/)
[![Support](https://img.shields.io/badge/support-active-green.svg)](documentation/TROUBLESHOOTING.md)

</div>
